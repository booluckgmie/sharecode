{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7611a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to data_gso\\2025-07-13.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "from pytz import timezone\n",
    "from urllib3.exceptions import MaxRetryError, ConnectionError\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "try:\n",
    "    # Specify the URL and data\n",
    "    url = \"https://www.gso.org.my/SystemData/CurrentGen.aspx/GetChartDataSource\"\n",
    "    data = {\n",
    "        \"Fromdate\": datetime.now().strftime('%d/%m/%Y'),\n",
    "        \"Todate\": datetime.now().strftime('%d/%m/%Y')\n",
    "    }\n",
    "\n",
    "    # Set headers\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Make a POST request\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        # Extract and process data\n",
    "        chartobjdata_list = json.loads(json.loads(response.text)[\"d\"])\n",
    "        flattened_data = [\n",
    "            {\n",
    "                \"datetime\": entry[\"DT\"],\n",
    "                \"Coal\": entry[\"Coal\"],\n",
    "                \"Gas\": entry[\"Gas\"],\n",
    "                \"CoGen\": entry[\"CoGen\"],\n",
    "                \"Oil\": entry[\"Oil\"],\n",
    "                \"Hydro\": entry[\"Hydro\"],\n",
    "                \"Solar\": entry[\"Solar\"]\n",
    "            } for entry in chartobjdata_list\n",
    "        ]\n",
    "\n",
    "        # Convert flattened data to DataFrame\n",
    "        df = pd.DataFrame(flattened_data)\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "        # Split \"datetime\" into \"date\" and \"time\" columns\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "        df['time'] = df['datetime'].dt.time\n",
    "\n",
    "        # Select specific columns\n",
    "        df = df.loc[:, ['date', 'time', 'Coal', 'Gas', 'CoGen', 'Oil', 'Hydro', 'Solar']]\n",
    "\n",
    "        # Save data to CSV using flattened_data\n",
    "        data_dir = 'data_gso'\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "        file_date = datetime.today()\n",
    "        file_name = file_date.strftime('%Y-%m-%d.csv')\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            existing_data = pd.read_csv(file_path, header=0)\n",
    "            combined_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "            combined_data.to_csv(file_path, index=False)\n",
    "            print(f'Data has been appended to {file_path}')\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f'Data has been saved to {file_path}')\n",
    "\n",
    "    else:\n",
    "        print(\"Error: Unable to retrieve chart data. Status Code:\", response.status_code)\n",
    "\n",
    "except (RequestException, ConnectionError, MaxRetryError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # You can add further error handling or logging here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530450f",
   "metadata": {},
   "source": [
    "## march 2025 till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched data for 01/03/2025\n",
      "Successfully fetched data for 02/03/2025\n",
      "Successfully fetched data for 03/03/2025\n",
      "Successfully fetched data for 04/03/2025\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "from urllib3.exceptions import MaxRetryError, ConnectionError\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "try:\n",
    "    # Specify the URL\n",
    "    url = \"https://www.gso.org.my/SystemData/CurrentGen.aspx/GetChartDataSource\"\n",
    "\n",
    "    # Set headers\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime(2025, 3, 1)\n",
    "    end_date = datetime.now()\n",
    "    \n",
    "    # Initialize an empty list to store all fetched data\n",
    "    all_flattened_data = []\n",
    "\n",
    "    # Loop through each day from start_date to end_date\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        from_date_str = current_date.strftime('%d/%m/%Y')\n",
    "        to_date_str = current_date.strftime('%d/%m/%Y') # Fetch data for one day at a time\n",
    "\n",
    "        data = {\n",
    "            \"Fromdate\": from_date_str,\n",
    "            \"Todate\": to_date_str\n",
    "        }\n",
    "\n",
    "        # Make a POST request\n",
    "        response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "\n",
    "        # Check the response status\n",
    "        if response.status_code == 200:\n",
    "            # Extract and process data for the current day\n",
    "            chartobjdata_list = json.loads(json.loads(response.text)[\"d\"])\n",
    "            flattened_data = [\n",
    "                {\n",
    "                    \"datetime\": entry[\"DT\"],\n",
    "                    \"Coal\": entry[\"Coal\"],\n",
    "                    \"Gas\": entry[\"Gas\"],\n",
    "                    \"CoGen\": entry[\"CoGen\"],\n",
    "                    \"Oil\": entry[\"Oil\"],\n",
    "                    \"Hydro\": entry[\"Hydro\"],\n",
    "                    \"Solar\": entry[\"Solar\"]\n",
    "                } for entry in chartobjdata_list\n",
    "            ]\n",
    "            all_flattened_data.extend(flattened_data)\n",
    "            print(f\"Successfully fetched data for {from_date_str}\")\n",
    "        else:\n",
    "            print(f\"Error: Unable to retrieve chart data for {from_date_str}. Status Code: {response.status_code}\")\n",
    "        \n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    if all_flattened_data:\n",
    "        # Convert all flattened data to DataFrame\n",
    "        df = pd.DataFrame(all_flattened_data)\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "        # Split \"datetime\" into \"date\" and \"time\" columns\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "        df['time'] = df['datetime'].dt.time\n",
    "\n",
    "        # Select specific columns\n",
    "        df = df.loc[:, ['date', 'time', 'Coal', 'Gas', 'CoGen', 'Oil', 'Hydro', 'Solar']]\n",
    "\n",
    "        # Sort the DataFrame by date and time to ensure proper appending\n",
    "        df = df.sort_values(by=['date', 'time']).drop_duplicates()\n",
    "\n",
    "        # Save data to CSV\n",
    "        data_dir = 'data_gso'\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "        # We'll save all data in a single file named with the current date, but containing data from May 1st\n",
    "        file_name = f\"generation_data_from_{start_date.strftime('%Y-%m-%d')}_to_current.csv\"\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            existing_data = pd.read_csv(file_path, parse_dates={'datetime_full': ['date', 'time']})\n",
    "            # To avoid duplicates when appending, we can convert both to datetime and then drop duplicates\n",
    "            df['datetime_full'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'].astype(str))\n",
    "            \n",
    "            combined_data = pd.concat([existing_data, df], ignore_index=True)\n",
    "            # Drop duplicates based on the 'datetime_full' column (or original 'DT' equivalent)\n",
    "            combined_data.drop_duplicates(subset=['datetime_full'], inplace=True)\n",
    "            # Re-select the original columns for saving\n",
    "            combined_data = combined_data.loc[:, ['date', 'time', 'Coal', 'Gas', 'CoGen', 'Oil', 'Hydro', 'Solar']]\n",
    "            combined_data.to_csv(file_path, index=False)\n",
    "            print(f'Data has been appended and de-duplicated to {file_path}')\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f'Data has been saved to {file_path}')\n",
    "    else:\n",
    "        print(\"No data was fetched for the specified date range.\")\n",
    "\n",
    "except (RequestException, ConnectionError, MaxRetryError) as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    # You can add further error handling or logging here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a62d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
