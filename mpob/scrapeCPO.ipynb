{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d42dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded02b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping complete. Data saved to 'cpo_daily_prices.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_year(year):\n",
    "    url = f\"https://bepi.mpob.gov.my/admin2/price_local_daily_view_cpo_msia.php?more=Y&jenis=1Y&tahun={year}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    table = soup.find(\"tbody\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # Extract month headers\n",
    "    header_row = None\n",
    "    for row in rows:\n",
    "        if row.find_all(\"td\") and \"Date\" in row.get_text():\n",
    "            header_row = row\n",
    "            break\n",
    "\n",
    "    if not header_row:\n",
    "        raise ValueError(f\"Month headers not found for year {year}\")\n",
    "    \n",
    "    months = [td.get_text(strip=True) for td in header_row.find_all(\"td\")[1:]]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) == 13 and cols[0].get_text(strip=True).isdigit():\n",
    "            day = cols[0].get_text(strip=True).zfill(2)\n",
    "            for i, value_td in enumerate(cols[1:], start=0):\n",
    "                value = value_td.get_text(strip=True).replace(\",\", \"\")\n",
    "                if value not in ['-', '']:\n",
    "                    data.append({\n",
    "                        \"year\": year,\n",
    "                        \"month\": months[i],\n",
    "                        \"day\": day,\n",
    "                        \"price\": value\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Combine data for 2023, 2024, 2025\n",
    "years = [2023, 2024, 2025]\n",
    "all_data = pd.concat([scrape_year(year) for year in years], ignore_index=True)\n",
    "\n",
    "# Format date\n",
    "all_data[\"date\"] = pd.to_datetime(all_data[\"day\"] + \" \" + all_data[\"month\"] + \" \" + all_data[\"year\"].astype(str), errors='coerce', dayfirst=True)\n",
    "all_data = all_data.dropna(subset=[\"date\"])\n",
    "\n",
    "# Final formatting\n",
    "all_data = all_data[[\"date\", \"price\"]].sort_values(\"date\")\n",
    "all_data[\"price\"] = all_data[\"price\"].apply(lambda x: x if x in [\"PH\", \"NT\"] else float(x))\n",
    "\n",
    "# Export to CSV\n",
    "all_data.to_csv(\"cpo_daily_prices.csv\", index=False)\n",
    "\n",
    "print(\"✅ Scraping complete. Data saved to 'cpo_daily_prices.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba5b00",
   "metadata": {},
   "source": [
    "Crude Palm Oil (Local Delivered)<br>\n",
    "Minyak Sawit Mentah (Hantaran Tempatan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bc8a5",
   "metadata": {},
   "source": [
    "Note : <br>\n",
    "     1) All prices are weighted average / Semua harga dalam purata wajaran <br>\n",
    "     2) Price to be revised accordingly at 8.30am & 4.30pm / Harga akan dikemaskini pada jam 8.30 pagi & 4.30 petang. <br>\n",
    "\n",
    "Legend : <br>\n",
    "         ** - Price as at 8.30 AM / Harga adalah sehingga 8.30 pagi.<br>\n",
    "         NT - No Trade / Tiada Urusniaga<br>\n",
    "         PH : Public Holiday / Cuti Am<br>\n",
    "<br>\n",
    "Last update : 1/08/2025   4.30 pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8369bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-15 updated: 126.0 → 4126.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def scrape_today(year):\n",
    "    url = f\"https://bepi.mpob.gov.my/admin2/price_local_daily_view_cpo_msia.php?more=Y&jenis=1Y&tahun={year}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"tbody\")\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    months = []\n",
    "    for row in rows:\n",
    "        if row.find_all(\"td\") and \"Date\" in row.get_text():\n",
    "            months = [td.get_text(strip=True) for td in row.find_all(\"td\")[1:]]\n",
    "            break\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) == 13 and cols[0].get_text(strip=True).isdigit():\n",
    "            day = cols[0].get_text(strip=True).zfill(2)\n",
    "            for i, value_td in enumerate(cols[1:], start=0):\n",
    "                value = value_td.get_text(strip=True).replace(\",\", \"\")\n",
    "                if value not in ['-', '']:\n",
    "                    record = {\n",
    "                        \"year\": year,\n",
    "                        \"month\": months[i],\n",
    "                        \"day\": day,\n",
    "                        \"price\": value\n",
    "                    }\n",
    "                    data.append(record)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"day\"] + \" \" + df[\"month\"] + \" \" + df[\"year\"].astype(str), errors='coerce', dayfirst=True)\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "    df[\"price\"] = df[\"price\"].apply(lambda x: x if x in [\"PH\", \"NT\"] else float(x))\n",
    "    return df[[\"date\", \"price\"]]\n",
    "\n",
    "def prices_are_equal(price1, price2):\n",
    "    \"\"\"Compare two prices, handling different data types properly\"\"\"\n",
    "    # Convert both to string for comparison to handle mixed types\n",
    "    return str(price1) == str(price2)\n",
    "\n",
    "def update_csv():\n",
    "    if datetime.now().hour < 10:\n",
    "        return  # Run only after 10 AM\n",
    "\n",
    "    year = datetime.now().year\n",
    "    df_scraped = scrape_today(year)\n",
    "    csv_file = \"cpo_daily_prices.csv\"\n",
    "\n",
    "    if os.path.exists(csv_file):\n",
    "        df_existing = pd.read_csv(csv_file, parse_dates=[\"date\"])\n",
    "    else:\n",
    "        df_existing = pd.DataFrame(columns=[\"date\", \"price\"])\n",
    "\n",
    "    df_existing.set_index(\"date\", inplace=True)\n",
    "    df_scraped.set_index(\"date\", inplace=True)\n",
    "\n",
    "    changes = []\n",
    "\n",
    "    # Detect updates (date exists and price changed)\n",
    "    common_dates = df_scraped.index.intersection(df_existing.index)\n",
    "    for date in common_dates:\n",
    "        new_price = df_scraped.loc[date, \"price\"]\n",
    "        old_price = df_existing.loc[date, \"price\"]\n",
    "        # Only add to changes if prices are actually different\n",
    "        if not prices_are_equal(old_price, new_price):\n",
    "            df_existing.loc[date, \"price\"] = new_price\n",
    "            changes.append((date.date(), old_price, new_price))\n",
    "\n",
    "    # Detect new additions\n",
    "    new_dates = df_scraped.index.difference(df_existing.index)\n",
    "    for date in new_dates:\n",
    "        new_price = df_scraped.loc[date, \"price\"]\n",
    "        df_existing.loc[date] = new_price\n",
    "        changes.append((date.date(), None, new_price))\n",
    "\n",
    "    # Save updated file\n",
    "    df_existing.sort_index().reset_index().to_csv(csv_file, index=False)\n",
    "\n",
    "    # Print only actual changes\n",
    "    for date, old, new in changes:\n",
    "        print(f\"{date} updated: {old} → {new}\")\n",
    "\n",
    "# Run it\n",
    "update_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64166e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
